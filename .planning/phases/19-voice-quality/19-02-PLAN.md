---
phase: 19-voice-quality
plan: 02
type: execute
wave: 2
depends_on: ["19-01"]
files_modified:
  - app/(chat)/api/voice/route.ts
  - app/(chat)/api/realtime/stream/route.ts
  - hooks/use-greeting-speech.ts
autonomous: true

must_haves:
  truths:
    - "Collaborative multi-voice audio plays without glitches at segment boundaries"
    - "Collaborative segments use the streaming TTS endpoint for faster first-byte"
    - "Greeting audio does not auto-play on page load — requires user gesture"
  artifacts:
    - path: "app/(chat)/api/voice/route.ts"
      provides: "Collaborative audio with request stitching and streaming endpoint"
      contains: "previous_request_ids"
    - path: "app/(chat)/api/realtime/stream/route.ts"
      provides: "Collaborative audio with request stitching and streaming endpoint"
      contains: "previous_request_ids"
    - path: "hooks/use-greeting-speech.ts"
      provides: "User gesture gated greeting audio"
      contains: "handleUserGesture"
  key_links:
    - from: "app/(chat)/api/voice/route.ts"
      to: "ElevenLabs API"
      via: "sequential generation with request-id header capture"
      pattern: "response\\.headers\\.get.*request-id"
    - from: "app/(chat)/api/realtime/stream/route.ts"
      to: "ElevenLabs API"
      via: "sequential generation with request-id header capture"
      pattern: "response\\.headers\\.get.*request-id"
    - from: "hooks/use-greeting-speech.ts"
      to: "document event listeners"
      via: "click/keydown event listeners before first audio play"
      pattern: "addEventListener.*click.*handleUserGesture"
---

<objective>
Fix collaborative audio quality with ElevenLabs request stitching and gate greeting audio behind user gesture.

Purpose: VOICE-01 (critical — raw buffer concatenation produces pops/clicks at segment boundaries), VOICE-03 (collaborative segments use non-streaming endpoint doubling latency), and VOICE-05 (greeting auto-plays violating browser autoplay policies, fails silently in production).

Output: Collaborative mode generates segments sequentially with request stitching for prosody-aligned audio via the streaming endpoint, and greeting audio waits for user interaction before playing.
</objective>

<execution_context>
@/home/qualia/.claude/get-shit-done/workflows/execute-plan.md
@/home/qualia/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-voice-quality/19-RESEARCH.md
@.planning/phases/19-voice-quality/19-01-SUMMARY.md

@app/(chat)/api/voice/route.ts
@app/(chat)/api/realtime/stream/route.ts
@hooks/use-greeting-speech.ts
@lib/ai/voice-config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement request stitching for collaborative segments (VOICE-01, VOICE-03)</name>
  <files>app/(chat)/api/voice/route.ts, app/(chat)/api/realtime/stream/route.ts</files>
  <action>
  Rewrite the collaborative audio generation in both `app/(chat)/api/voice/route.ts` and `app/(chat)/api/realtime/stream/route.ts` to use ElevenLabs request stitching with `previous_request_ids`.

  **Changes to `generateAudioForSegment` in both files:**

  The function signature needs to change to accept and return request IDs for sequential chaining. Create a new helper (or modify the existing one) that:

  1. Accepts `previousRequestIds: string[]` as a parameter
  2. Uses the streaming endpoint: change URL from `/v1/text-to-speech/${voiceConfig.voiceId}` to `/v1/text-to-speech/${voiceConfig.voiceId}/stream`
  3. Adds `previous_request_ids: previousRequestIds.slice(-3)` to the JSON body (max 3 per ElevenLabs docs, 2-hour expiry)
  4. Includes `optimize_streaming_latency: 2` (from Plan 01)
  5. Captures the `request-id` from response headers: `response.headers.get('request-id')`
  6. Returns both the audio buffer AND the request ID: `{ buffer: ArrayBuffer, requestId: string | null }`

  **Changes to collaborative generation path in `app/(chat)/api/voice/route.ts`:**

  Replace the `Promise.all` pattern (around line 128-141) with sequential generation:
  ```
  const audioBuffers: ArrayBuffer[] = [];
  const previousRequestIds: string[] = [];

  for (const segment of validSegments) {
    const voiceConfig = getVoiceConfig(segment.speaker);
    const result = await generateAudioForSegment(
      segment.text,
      voiceConfig,
      apiKey,
      previousRequestIds,
    );
    audioBuffers.push(result.buffer);
    if (result.requestId) {
      previousRequestIds.push(result.requestId);
    }
  }
  ```

  Remove the `AbortController` that was used with `Promise.all` (no longer needed for sequential). Keep the existing timeout inside `generateAudioForSegment` via `withElevenLabsResilience`.

  The buffer concatenation after the loop stays the same — but now the buffers are prosody-aligned by ElevenLabs, so concatenation won't produce glitches.

  **Changes to collaborative generation path in `app/(chat)/api/realtime/stream/route.ts`:**

  Same pattern — replace `Promise.all` (around line 220-229) with sequential `for...of` loop with request ID capture. The `generateAudioForSegment` function at the top of this file also needs the same modifications (streaming endpoint, previous_request_ids, return requestId).

  **Important:** The `externalSignal` parameter on the voice route's `generateAudioForSegment` can be removed since we're no longer using `Promise.all` with an external AbortController. Each segment has its own timeout via `withElevenLabsResilience`.

  **Important:** The single-voice path in both routes stays unchanged (no request stitching needed for single segments). Only the collaborative multi-segment path changes.
  </action>
  <verify>
  Run `pnpm lint` to confirm no errors. Grep both files for `previous_request_ids` to confirm request stitching is present. Grep both files for `Promise.all` in the collaborative path to confirm it's been replaced with sequential generation. Grep both files for `/stream` in ElevenLabs URLs to confirm streaming endpoint is used for collaborative segments.
  </verify>
  <done>
  Both voice routes generate collaborative segments sequentially with `previous_request_ids` for prosody-aligned audio. Both use the streaming endpoint (`/stream`) for collaborative segments. No `Promise.all` remains in collaborative generation paths. Single-voice paths are unchanged.
  </done>
</task>

<task type="auto">
  <name>Task 2: Gate greeting audio behind user gesture (VOICE-05)</name>
  <files>hooks/use-greeting-speech.ts</files>
  <action>
  Fix `hooks/use-greeting-speech.ts` to comply with browser autoplay policies. Currently the hook fires `speak()` after a 500ms `setTimeout` on mount (lines 158-161), which violates Chrome/Firefox/Safari autoplay policies and silently fails in production.

  Replace the `setTimeout` approach in the `useEffect` (lines 137-166) with user gesture detection:

  1. Keep the `sessionStorage` check (lines 143-149) — if already greeted this session, skip
  2. Instead of `setTimeout(() => speak(...), 500)`, register event listeners for user interaction:
     ```
     const handleUserGesture = () => {
       if (hasGreetedRef.current) return;
       hasGreetedRef.current = true;
       sessionStorage.setItem(SESSION_KEY, 'true');

       document.removeEventListener('click', handleUserGesture);
       document.removeEventListener('keydown', handleUserGesture);

       const greetingText = GREETINGS[botType];
       speak(greetingText);
     };

     document.addEventListener('click', handleUserGesture, { once: true });
     document.addEventListener('keydown', handleUserGesture, { once: true });
     ```
  3. Move `hasGreetedRef.current = true` and `sessionStorage.setItem` INTO the gesture handler (not before it, as the current code does on lines 152-155). The current code marks as greeted immediately even if the greeting never plays.
  4. Clean up event listeners in the useEffect return function:
     ```
     return () => {
       document.removeEventListener('click', handleUserGesture);
       document.removeEventListener('keydown', handleUserGesture);
     };
     ```
  5. Remove the `setTimeout` and `clearTimeout` pattern entirely

  The `speak` callback, `stop` callback, cleanup effect, and return values all stay the same. Only the trigger mechanism changes from "auto after 500ms" to "on first user interaction".
  </action>
  <verify>
  Run `pnpm lint` to confirm no errors. Grep for `setTimeout` in the file to confirm it's been removed from the greeting trigger (note: it may still exist elsewhere in the file for other purposes — check context). Grep for `addEventListener.*click` to confirm user gesture detection is present. Grep for `handleUserGesture` to confirm the handler exists.
  </verify>
  <done>
  Greeting audio waits for first user click or keydown before playing. No `setTimeout` auto-play on mount. sessionStorage marking happens only when greeting actually fires. Event listeners are properly cleaned up on unmount.
  </done>
</task>

</tasks>

<verification>
1. `pnpm lint` passes with no errors
2. Both voice route files contain `previous_request_ids` (request stitching active)
3. Both voice route files use `/stream` endpoint for collaborative segments
4. No `Promise.all` in collaborative generation paths
5. `hooks/use-greeting-speech.ts` has no `setTimeout` for auto-play trigger
6. `hooks/use-greeting-speech.ts` has `addEventListener('click', ...)` for user gesture gate
7. All collaborative segment generation is sequential (for...of loop, not Promise.all)
</verification>

<success_criteria>
- VOICE-01: Collaborative segments use previous_request_ids for prosody-aligned concatenation (no pops/clicks)
- VOICE-03: Collaborative segments use /stream endpoint for lower TTFB
- VOICE-05: Greeting audio requires user click/keydown before playing (no auto-play on load)
- Both voice routes handle collaborative mode sequentially with request ID chaining
- Greeting hook properly cleans up event listeners
</success_criteria>

<output>
After completion, create `.planning/phases/19-voice-quality/19-02-SUMMARY.md`
</output>
