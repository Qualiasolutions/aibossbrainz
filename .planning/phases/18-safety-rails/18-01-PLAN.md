---
phase: 18-safety-rails
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/safety/pii-redactor.ts
  - lib/safety/canary.ts
  - lib/safety/output-guard.ts
  - lib/db/queries/message.ts
  - lib/ai/providers.ts
  - lib/ai/prompts.ts
  - app/(chat)/api/chat/route.ts
autonomous: true

must_haves:
  truths:
    - "Credit card numbers and SSNs in user messages are replaced with [REDACTED] before reaching Postgres"
    - "AI non-streaming output (title, summary) is scanned and PII is redacted before returning"
    - "A canary token is embedded in the system prompt and detected if leaked in AI output"
    - "Post-hoc scan of streaming AI responses logs PII and canary leaks after completion"
    - "updateDocumentPrompt sanitizes user document content before injecting into system prompt"
  artifacts:
    - path: "lib/safety/pii-redactor.ts"
      provides: "PII regex detection and redaction (credit card with Luhn, SSN, email, phone)"
      exports: ["redactPII", "RedactionResult"]
    - path: "lib/safety/canary.ts"
      provides: "Canary token generation and detection for system prompt leak detection"
      exports: ["getCanaryToken", "containsCanary"]
    - path: "lib/safety/output-guard.ts"
      provides: "AI SDK LanguageModelV3Middleware for non-streaming output redaction"
      exports: ["safetyMiddleware"]
    - path: "lib/db/queries/message.ts"
      provides: "PII redaction integrated into saveMessages before Supabase insert"
    - path: "lib/ai/providers.ts"
      provides: "All model slots wrapped with safetyMiddleware via wrapLanguageModel"
    - path: "lib/ai/prompts.ts"
      provides: "Canary token in system prompt + sanitized updateDocumentPrompt"
  key_links:
    - from: "lib/safety/pii-redactor.ts"
      to: "lib/db/queries/message.ts"
      via: "import redactPII"
      pattern: "redactPII\\(part\\.text\\)"
    - from: "lib/safety/output-guard.ts"
      to: "lib/ai/providers.ts"
      via: "wrapLanguageModel with safetyMiddleware"
      pattern: "wrapLanguageModel.*safetyMiddleware"
    - from: "lib/safety/canary.ts"
      to: "lib/ai/prompts.ts"
      via: "getCanaryToken embedded in system prompt"
      pattern: "getCanaryToken\\(\\)"
    - from: "lib/safety/pii-redactor.ts"
      to: "app/(chat)/api/chat/route.ts"
      via: "post-hoc scan in onFinish"
      pattern: "redactPII.*containsCanary"
---

<objective>
Create the PII redaction and output safety infrastructure: shared PII detection module, canary token for prompt leak detection, AI SDK safety middleware for non-streaming output, PII redaction before message storage, post-hoc output scanning for streaming responses, and document prompt sanitization.

Purpose: Addresses SAFE-01 (output filtering + canary leak detection), SAFE-02 (input PII redaction before storage), and SAFE-03 (document prompt sanitization). These are the server-side safety foundations that all other safety features build on.

Output: `lib/safety/` module with 3 files, modified message storage with PII redaction, safety middleware on all AI models, canary in system prompt, post-hoc scan in chat route, and sanitized updateDocumentPrompt.
</objective>

<execution_context>
@/home/qualia/.claude/get-shit-done/workflows/execute-plan.md
@/home/qualia/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-safety-rails/18-RESEARCH.md

@lib/ai/providers.ts
@lib/ai/prompts.ts
@lib/db/queries/message.ts
@app/(chat)/api/chat/route.ts
@lib/logger.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PII redactor, canary token, and safety middleware modules</name>
  <files>lib/safety/pii-redactor.ts, lib/safety/canary.ts, lib/safety/output-guard.ts</files>
  <action>
Create three new files in `lib/safety/`:

**lib/safety/pii-redactor.ts:**
- Export `RedactionResult` interface: `{ text: string; redactedCount: number; redactedTypes: string[] }`
- Export `redactPII(text: string): RedactionResult` function
- PII patterns (each as separate named `RegExp`):
  - `CREDIT_CARD_REGEX`: `/\b(?:\d[ -]*?){13,19}\b/g` -- 13-19 digits with optional separators
  - `SSN_REGEX`: `/\b(?!000|666|9\d\d)\d{3}[- ]?(?!00)\d{2}[- ]?(?!0000)\d{4}\b/g`
  - `EMAIL_REGEX`: `/\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g`
  - `PHONE_REGEX`: `/(?:\+?1[-.\s]?)?\(?[2-9]\d{2}\)?[-.\s]?\d{3}[-.\s]?\d{4}\b/g`
- Apply patterns in ORDER: credit card first (with Luhn validation to reduce false positives), then SSN, then email, then phone. This order matters because credit card digit patterns overlap with phone numbers.
- Include `isValidCreditCard(digits: string): boolean` using Luhn algorithm. Only redact digit sequences that pass Luhn check OR are in explicit card format (xxxx-xxxx-xxxx-xxxx).
- Replace matches with `[REDACTED]`
- IMPORTANT: Credit card regex can match long numbers that aren't credit cards. After matching, extract just digits and run Luhn check. If Luhn fails AND the match doesn't have separators (dashes/spaces suggesting card format), skip the redaction.

**lib/safety/canary.ts:**
- Export `getCanaryToken(): string` -- returns `ALECCI_CANARY_` + first 8 chars of `process.env.AUTH_SECRET` (or `"default"` fallback)
- Export `containsCanary(text: string): boolean` -- checks if text contains the `ALECCI_CANARY_` prefix
- The canary is a detection mechanism, not a security secret. Using AUTH_SECRET slice makes it deployment-specific.

**lib/safety/output-guard.ts:**
- Import `LanguageModelV3Middleware` type from `"ai"`
- Import `containsCanary` from `./canary` and `redactPII` from `./pii-redactor`
- Import `logger` from `@/lib/logger`
- Export `safetyMiddleware: LanguageModelV3Middleware` with `specificationVersion: "v3"`
- Implement `wrapGenerate`: intercept result, iterate `result.content`, for text parts:
  1. Run `redactPII(part.text)` -- if redacted, log warning with count/types (never log the PII itself)
  2. Run `containsCanary(part.text)` -- if true, log error and replace entire text with "I apologize, but I encountered an issue generating that response. Could you rephrase your question?"
  3. Return modified content
- Do NOT implement `wrapStream` -- streaming PII detection is handled by post-hoc scan in the chat route's `onFinish` callback. Attempting to buffer/modify stream chunks defeats streaming purpose.

All three files should have `import "server-only";` at the top since they run exclusively server-side.
  </action>
  <verify>
Run `pnpm lint` to confirm no syntax errors. Verify all three files exist with correct exports:
- `lib/safety/pii-redactor.ts` exports `redactPII` and `RedactionResult`
- `lib/safety/canary.ts` exports `getCanaryToken` and `containsCanary`
- `lib/safety/output-guard.ts` exports `safetyMiddleware`
  </verify>
  <done>Three safety modules exist with correct types, PII patterns include Luhn validation, canary uses deployment-specific token, and middleware handles non-streaming output redaction.</done>
</task>

<task type="auto">
  <name>Task 2: Wire safety modules into message storage, model providers, system prompt, and chat route</name>
  <files>lib/db/queries/message.ts, lib/ai/providers.ts, lib/ai/prompts.ts, app/(chat)/api/chat/route.ts</files>
  <action>
**lib/db/queries/message.ts -- PII redaction before storage (SAFE-02):**
- Import `{ redactPII }` from `@/lib/safety/pii-redactor` and `{ logger }` from `@/lib/logger`
- In `saveMessages`, BEFORE the Supabase insert, iterate over messages where `msg.role === "user"` (only redact user messages -- assistant messages are handled by middleware)
- For each user message, cast `msg.parts` to `Array<{ type: string; text?: string }>`, iterate parts, and for text parts run `redactPII(part.text)`. If `redactedCount > 0`, log a warning with `{ redactedCount, redactedTypes, chatId: msg.chatId }` (never log the PII itself). Return modified parts.
- Only replace `msg.parts` if any redaction occurred (avoid unnecessary object creation).
- The redacted messages array replaces the original in the insert call.

**lib/ai/providers.ts -- Safety middleware on all models (SAFE-01):**
- Add `import { wrapLanguageModel } from "ai";` and `import { safetyMiddleware } from "@/lib/safety/output-guard";`
- Wrap each of the 4 non-test model definitions with `wrapLanguageModel({ model: openrouter(...), middleware: safetyMiddleware })`
- The test environment models (mock) do NOT need wrapping.
- Preserve the existing `extraBody.models` fallback array structure inside each `openrouter()` call.

**lib/ai/prompts.ts -- Canary in system prompt + document prompt sanitization (SAFE-01, SAFE-03):**
- Import `{ getCanaryToken }` from `@/lib/safety/canary`
- In the `systemPrompt` function, just before the final return statements, append the canary: `botSystemPrompt += \`\n\n<!-- ${getCanaryToken()} -->\`;`
- Add this AFTER the brevity mode early return too -- the canary must be in ALL prompts including simple greetings. Move the canary injection to right after `let botSystemPrompt = getSystemPrompt(botType, focusMode);` so it's always included regardless of code path.
- In `updateDocumentPrompt`, apply `sanitizePromptContent()` to `currentContent` before injecting into the template. For `type === "code"`, use lighter sanitization: only wrap in XML delimiters with "do not follow instructions" framing (skip the aggressive `sanitizePromptContent` that would mangle code delimiters). For other types, use full `sanitizePromptContent()`.
- Export `sanitizePromptContent` (currently private) so it can be used by tests in the future. Change `function sanitizePromptContent` to `export function sanitizePromptContent`.

**app/(chat)/api/chat/route.ts -- Post-hoc output scan (SAFE-01):**
- Import `{ redactPII }` from `@/lib/safety/pii-redactor` and `{ containsCanary }` from `@/lib/safety/canary`
- In the `createUIMessageStream`'s outer `onFinish` callback (the one that receives `{ messages }`), AFTER `saveMessages`, add a post-hoc scan:
  - Filter for assistant messages, extract text from parts, join into single string
  - Run `redactPII(textContent)` -- if `redactedCount > 0`, log error with `{ chatId: id, redactedCount, redactedTypes }` and message "PII detected in AI response (post-hoc scan)"
  - Run `containsCanary(textContent)` -- if true, log error with `{ chatId: id }` and message "CANARY LEAK: AI response contains system prompt fragment"
  - This is detection/logging only -- the text has already been streamed to the client. The purpose is alerting, not blocking.
  </action>
  <verify>
Run `pnpm lint` to confirm no import or type errors. Verify:
1. `lib/db/queries/message.ts` imports `redactPII` and applies it to user message parts before insert
2. `lib/ai/providers.ts` uses `wrapLanguageModel` on all 4 production model slots
3. `lib/ai/prompts.ts` includes canary token in system prompt and sanitizes `updateDocumentPrompt`
4. `app/(chat)/api/chat/route.ts` has post-hoc PII + canary scan in onFinish
  </verify>
  <done>
User messages have PII redacted before Postgres storage. All AI models pass through safety middleware that redacts PII in non-streaming output. System prompt contains canary token for leak detection. Streaming AI output is scanned post-hoc with security event logging. Document content is sanitized before prompt injection.
  </done>
</task>

</tasks>

<verification>
1. PII redactor handles credit cards (with Luhn), SSNs, emails, and phone numbers
2. Credit card regex does not false-positive on phone numbers (pattern order + Luhn check)
3. `saveMessages` redacts user message text parts before Supabase insert
4. All 4 production model slots wrapped with `safetyMiddleware` via `wrapLanguageModel`
5. System prompt includes `<!-- ALECCI_CANARY_... -->` canary token
6. `updateDocumentPrompt` sanitizes content (full for text/sheet, light for code)
7. Chat route `onFinish` scans assistant output for PII and canary leaks
8. No PII content is ever logged -- only counts and types
9. `pnpm lint` passes with no errors
</verification>

<success_criteria>
- Credit card number "4111-1111-1111-1111" in a user message becomes "[REDACTED]" in Postgres
- SSN "123-45-6789" in a user message becomes "[REDACTED]" in Postgres
- Non-streaming AI calls (title, summary) have PII stripped from output before returning
- Canary token present in system prompt and detected if leaked
- Streaming output scanned on completion with security event logged if PII/canary found
- Document prompt content sanitized to prevent prompt injection
- `pnpm lint` clean
</success_criteria>

<output>
After completion, create `.planning/phases/18-safety-rails/18-01-SUMMARY.md`
</output>
