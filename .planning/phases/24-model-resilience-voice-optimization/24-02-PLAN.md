---
phase: 24-model-resilience-voice-optimization
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/tts-cache.ts
  - app/(chat)/api/voice/route.ts
  - app/(chat)/api/realtime/route.ts
  - app/(chat)/api/realtime/stream/route.ts
autonomous: true

must_haves:
  truths:
    - "Repeated TTS requests for identical text+voice return cached audio URL from Vercel Blob instead of calling ElevenLabs"
    - "Collaborative voice mode isolates per-segment errors so one failed segment does not kill the entire response"
    - "Realtime routes return Vercel Blob CDN URLs instead of base64 data URLs for audio"
    - "Realtime non-stream route has rate limiting matching the stream route pattern"
    - "TTS cache misses fall through to ElevenLabs generation and store results for future hits"
    - "All segments failing in collaborative mode returns a 503 error, not a broken response"
  artifacts:
    - path: "lib/tts-cache.ts"
      provides: "TTS cache with content-addressable Vercel Blob storage"
      exports: ["getCachedAudio", "cacheAudio", "generateTTSCacheKey"]
    - path: "app/(chat)/api/voice/route.ts"
      provides: "TTS cache integration and per-segment error isolation in collaborative mode"
      contains: "getCachedAudio"
    - path: "app/(chat)/api/realtime/route.ts"
      provides: "Rate limiting and Blob URL audio instead of base64"
      contains: "checkRateLimit"
    - path: "app/(chat)/api/realtime/stream/route.ts"
      provides: "Blob URL audio instead of base64, per-segment error isolation"
      contains: "getCachedAudio"
  key_links:
    - from: "lib/tts-cache.ts"
      to: "@vercel/blob"
      via: "put/head for content-addressable audio storage"
      pattern: "import.*@vercel/blob"
    - from: "app/(chat)/api/voice/route.ts"
      to: "lib/tts-cache.ts"
      via: "getCachedAudio/cacheAudio for TTS dedup"
      pattern: "getCachedAudio|cacheAudio"
    - from: "app/(chat)/api/realtime/route.ts"
      to: "lib/security/rate-limiter"
      via: "checkRateLimit for abuse prevention"
      pattern: "checkRateLimit"
---

<objective>
Optimize voice features: implement TTS caching with Vercel Blob, add per-segment error isolation in collaborative mode, replace base64 data URLs with CDN URLs in realtime routes, and add rate limiting to the realtime non-stream route.

Purpose: Reduce ElevenLabs costs through audio caching, improve collaborative voice reliability, reduce response sizes by 33%, and prevent abuse of the realtime endpoint.
Output: New TTS cache module, updated voice routes with caching + error isolation, rate-limited realtime route.
</objective>

<execution_context>
@/home/qualia/.claude/get-shit-done/workflows/execute-plan.md
@/home/qualia/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/24-model-resilience-voice-optimization/24-RESEARCH.md
@app/(chat)/api/voice/route.ts
@app/(chat)/api/realtime/route.ts
@app/(chat)/api/realtime/stream/route.ts
@lib/ai/voice-config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TTS cache module and integrate into voice route with per-segment error isolation</name>
  <files>lib/tts-cache.ts, app/(chat)/api/voice/route.ts</files>
  <action>
**lib/tts-cache.ts (NEW FILE):**

Create a content-addressable TTS cache backed by Vercel Blob:

1. Define `TTSCacheParams` interface:
   ```typescript
   interface TTSCacheParams {
     text: string;
     voiceId: string;
     modelId: string;
     stability: number;
     similarityBoost: number;
     style: number;
     useSpeakerBoost: boolean;
   }
   ```

2. Export `generateTTSCacheKey(params: TTSCacheParams): string` that:
   - Creates a canonical JSON string with sorted keys (use a deterministic serialization)
   - Hashes with SHA-256: `createHash('sha256').update(canonicalJson).digest('hex')`
   - Returns `tts-cache/${hash}.mp3`
   - Import `createHash` from `node:crypto`

3. Export `getCachedAudio(params: TTSCacheParams): Promise<string | null>` that:
   - Generates the cache key
   - Calls `head(key)` from `@vercel/blob` to check existence
   - Returns `blob.url` on hit, `null` on miss (catch errors as miss)
   - Log cache hit/miss at debug level

4. Export `cacheAudio(params: TTSCacheParams, audioBuffer: ArrayBuffer): Promise<string>` that:
   - Generates the cache key
   - Calls `put(key, new Uint8Array(audioBuffer), { access: 'public', contentType: 'audio/mpeg', addRandomSuffix: false })`
   - `addRandomSuffix: false` is CRITICAL for deterministic cache lookup
   - Returns `blob.url` (CDN URL)
   - Wrap in try/catch -- on failure, log warning and return empty string (cache write failure should not break TTS)

5. Export a helper `buildCacheParams(text: string, voiceConfig: VoiceConfig): TTSCacheParams` that extracts all fields from VoiceConfig into the flat TTSCacheParams shape. Import VoiceConfig type from `@/lib/ai/voice-config`.

**app/(chat)/api/voice/route.ts:**

6. Import `getCachedAudio`, `cacheAudio`, `buildCacheParams` from `@/lib/tts-cache`.

7. In the **collaborative mode** segment loop (the `for (const segment of validSegments)` block starting around line 146), wrap each iteration in try/catch for per-segment error isolation:
   ```typescript
   const audioBuffers: ArrayBuffer[] = [];
   const previousRequestIds: string[] = [];
   const failedSegments: number[] = [];

   for (let i = 0; i < validSegments.length; i++) {
     const segment = validSegments[i];
     try {
       const voiceConfig = getVoiceConfig(segment.speaker);

       // Check TTS cache first
       const cacheParams = buildCacheParams(segment.text, voiceConfig);
       const cachedUrl = await getCachedAudio(cacheParams);

       if (cachedUrl) {
         // Cache hit - fetch audio from CDN
         const cachedResponse = await fetch(cachedUrl);
         const cachedBuffer = await cachedResponse.arrayBuffer();
         audioBuffers.push(cachedBuffer);
         continue; // Skip ElevenLabs call
       }

       // Cache miss - generate with ElevenLabs
       const result = await generateAudioForSegment(
         segment.text, voiceConfig, apiKey, previousRequestIds,
       );
       audioBuffers.push(result.buffer);
       if (result.requestId) previousRequestIds.push(result.requestId);

       // Cache the generated audio (fire-and-forget, don't await)
       cacheAudio(cacheParams, result.buffer).catch(() => {});
     } catch (err) {
       logger.warn({ err, segmentIndex: i, speaker: segment.speaker },
         'Collaborative segment TTS failed, skipping');
       failedSegments.push(i);
     }
   }

   if (audioBuffers.length === 0) {
     return Response.json(
       { error: 'Voice generation failed for all segments' },
       { status: 503 },
     );
   }
   ```
   If `failedSegments.length > 0`, log it but still return the partial audio from successful segments.

8. In the **single voice path** (around line 200, the `withElevenLabsResilience` call), add TTS cache before and after:
   - Before ElevenLabs call: check cache with `getCachedAudio(buildCacheParams(cleanText, voiceConfig))`
   - On cache hit: return cached audio as Response with `Content-Type: audio/mpeg`
   - After successful ElevenLabs call: read the response body into an ArrayBuffer, cache it, then return the audio
   - Note: the current code streams the ElevenLabs response body directly. To cache, you need to consume the body. Change the approach: consume response.arrayBuffer() from withElevenLabsResilience, cache the buffer, then return `new Response(buffer, ...)`.
  </action>
  <verify>
Run `pnpm build` -- no type errors. Verify lib/tts-cache.ts exists with exports. Grep for `getCachedAudio` in voice/route.ts. Grep for `failedSegments` in voice/route.ts to confirm error isolation.
  </verify>
  <done>
TTS cache module exists with content-addressable Vercel Blob storage. Voice route checks cache before calling ElevenLabs, caches new audio after generation. Collaborative mode isolates per-segment errors -- partial audio returned when some segments fail.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add rate limiting to realtime route and replace base64 with Blob URLs in both realtime routes</name>
  <files>app/(chat)/api/realtime/route.ts, app/(chat)/api/realtime/stream/route.ts</files>
  <action>
**app/(chat)/api/realtime/route.ts:**

1. Import `checkRateLimit`, `getRateLimitHeaders` from `@/lib/security/rate-limiter`, and `createServiceClient` from `@/lib/supabase/server`.

2. Add rate limiting AFTER auth check, BEFORE AI generation. Use the same pattern as the stream route:
   ```typescript
   const MAX_REALTIME_REQUESTS_PER_DAY = 200; // Match stream route limit

   const rateLimitResult = await checkRateLimit(
     `realtime:${user.id}`,
     MAX_REALTIME_REQUESTS_PER_DAY,
   );

   if (rateLimitResult.source === 'redis') {
     if (!rateLimitResult.allowed) {
       const response = new ChatSDKError('rate_limit:chat').toResponse();
       const headers = getRateLimitHeaders(
         rateLimitResult.remaining,
         MAX_REALTIME_REQUESTS_PER_DAY,
         rateLimitResult.reset,
       );
       for (const [key, value] of Object.entries(headers)) {
         response.headers.set(key, value);
       }
       return response;
     }
   } else {
     // Redis unavailable - verify via UserAnalytics (fail closed)
     const supabaseService = createServiceClient();
     const today = new Date();
     today.setHours(0, 0, 0, 0);
     const { data, error } = await supabaseService
       .from('UserAnalytics')
       .select('voiceMinutes')
       .eq('userId', user.id)
       .gte('date', today.toISOString())
       .maybeSingle();

     if (error) return new ChatSDKError('rate_limit:chat').toResponse();
     if ((Number(data?.voiceMinutes) || 0) >= MAX_REALTIME_REQUESTS_PER_DAY) {
       return new ChatSDKError('rate_limit:chat').toResponse();
     }
   }
   ```

3. Import `getCachedAudio`, `cacheAudio`, `buildCacheParams` from `@/lib/tts-cache` and `getVoiceConfig` is already imported.

4. Replace the base64 audio generation (the `Buffer.from(audioData).toString("base64")` + `data:audio/mpeg;base64,...` pattern around line 153) with Blob URL caching:
   ```typescript
   // Instead of base64:
   const voiceConfig = getVoiceConfig(botType);
   const cacheParams = buildCacheParams(cleanText, voiceConfig);
   const cachedUrl = await getCachedAudio(cacheParams);

   if (cachedUrl) {
     audioUrl = cachedUrl;
   } else {
     // Generate with ElevenLabs (existing code to get audioData)
     // After getting audioData (ArrayBuffer):
     const blobUrl = await cacheAudio(cacheParams, audioData);
     audioUrl = blobUrl || null; // Fall back to null if cache write failed
   }
   ```
   Remove ALL `Buffer.from(...).toString("base64")` and `data:audio/mpeg;base64,` patterns. The `audioUrl` field in the JSON response now contains a CDN URL string (or null if audio generation failed).

**app/(chat)/api/realtime/stream/route.ts:**

5. Import `getCachedAudio`, `cacheAudio`, `buildCacheParams` from `@/lib/tts-cache`.

6. Apply the same base64-to-Blob-URL replacement pattern:

   For the **collaborative path** (around line 238-277):
   - Add per-segment error isolation matching the pattern from Task 1 (try/catch per segment with `failedSegments` tracking)
   - Add TTS cache lookup per segment (same as voice route Task 1)
   - Replace `Buffer.from(combined).toString("base64")` + `data:audio/...` with Blob URL caching of the combined audio
   - After concatenating successful segment buffers, cache the combined audio and use the returned URL

   For the **single voice path** (around line 278-290):
   - Add TTS cache lookup before ElevenLabs call
   - On cache hit, use cached URL directly
   - On miss, generate audio, cache it, use Blob URL
   - Remove `Buffer.from(audioData).toString("base64")` pattern

7. Verify NO remaining `base64` or `data:audio` patterns exist in either realtime route after changes.
  </action>
  <verify>
Run `pnpm build` -- no type errors. Run `pnpm lint`. Grep for `base64` in both realtime routes to confirm removal. Grep for `getCachedAudio` in both routes. Grep for `checkRateLimit` in realtime/route.ts. Grep for `failedSegments` in realtime/stream/route.ts.
  </verify>
  <done>
Realtime non-stream route has rate limiting matching stream route. Both realtime routes return Vercel Blob CDN URLs instead of base64 data URLs. Collaborative mode in stream route has per-segment error isolation. All TTS calls are cached via Vercel Blob.
  </done>
</task>

</tasks>

<verification>
1. `pnpm build` passes with no type errors
2. `pnpm lint` passes
3. `grep -r "base64" app/(chat)/api/realtime/` returns NO matches (all base64 removed)
4. `grep -r "getCachedAudio" app/(chat)/api/voice/ app/(chat)/api/realtime/` shows cache usage in all voice routes
5. `grep -r "checkRateLimit" app/(chat)/api/realtime/route.ts` shows rate limiting added
6. `grep -r "failedSegments" app/(chat)/api/voice/route.ts app/(chat)/api/realtime/stream/route.ts` shows error isolation
7. `ls lib/tts-cache.ts` confirms new module exists
</verification>

<success_criteria>
- TTS cache module provides content-addressable audio storage with SHA-256 hashing of all voice parameters
- Voice route and both realtime routes check cache before calling ElevenLabs
- Collaborative mode continues generating remaining segments when one segment fails
- Realtime routes return CDN URLs instead of 33%-bloated base64 data URLs
- Realtime non-stream route has rate limiting preventing unbounded AI/TTS costs
- Cache write failures are logged but do not break audio generation
</success_criteria>

<output>
After completion, create `.planning/phases/24-model-resilience-voice-optimization/24-02-SUMMARY.md`
</output>
