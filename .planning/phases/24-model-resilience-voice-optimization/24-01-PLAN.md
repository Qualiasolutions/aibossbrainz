---
phase: 24-model-resilience-voice-optimization
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/resilience.ts
  - lib/ai/providers.ts
  - lib/ai/conversation-summarizer.ts
  - app/api/health/route.ts
  - app/(chat)/api/chat/route.ts
autonomous: true
user_setup:
  - service: google-ai
    why: "Secondary AI provider fallback when OpenRouter is down"
    env_vars:
      - name: GOOGLE_AI_API_KEY
        source: "Google AI Studio -> Get API Key (https://aistudio.google.com/apikey)"
    dashboard_config: []

must_haves:
  truths:
    - "Circuit breaker only opens on transient errors (429, 5xx, network), not on 400/401/403 client errors"
    - "Retry logic respects Retry-After headers from OpenRouter instead of using fixed backoff"
    - "When OpenRouter is completely down and GOOGLE_AI_API_KEY is set, chat falls back to direct Google Gemini"
    - "When GOOGLE_AI_API_KEY is not set, app works fine with only OpenRouter (no crash)"
    - "Conversation summarizer validates AI JSON output with Zod schema and returns null on invalid data"
    - "Health check probes OpenRouter reachability and reports latency"
  artifacts:
    - path: "lib/resilience.ts"
      provides: "Retry-after parsing, transient error classification helper"
      contains: "getRetryAfterMs"
    - path: "lib/ai/providers.ts"
      provides: "Fallback provider chain with ai-fallback"
      contains: "createFallback"
    - path: "lib/ai/conversation-summarizer.ts"
      provides: "Zod-validated summary parsing"
      contains: "safeParse"
    - path: "app/api/health/route.ts"
      provides: "OpenRouter health probe"
      contains: "probeOpenRouter"
    - path: "app/(chat)/api/chat/route.ts"
      provides: "Transient-only circuit breaker recording"
      contains: "isTransientError"
  key_links:
    - from: "lib/resilience.ts"
      to: "app/(chat)/api/chat/route.ts"
      via: "isTransientError used before recordCircuitFailure"
      pattern: "isTransientError.*recordCircuitFailure"
    - from: "lib/ai/providers.ts"
      to: "ai-fallback"
      via: "createFallback wrapping OpenRouter + Google direct"
      pattern: "createFallback"
    - from: "app/api/health/route.ts"
      to: "https://openrouter.ai/api/v1/key"
      via: "HTTP probe with 5s timeout"
      pattern: "openrouter\\.ai/api/v1/key"
---

<objective>
Harden AI provider resilience: fix circuit breaker error classification, add retry-after header parsing, implement provider-level fallback to direct Google Gemini, add Zod validation to conversation summarizer, and add OpenRouter health probe.

Purpose: Prevent circuit breaker false positives from client errors, respect provider rate limits, survive complete OpenRouter outages, and validate AI-generated JSON.
Output: Updated resilience module, provider chain with ai-fallback, validated summarizer, health probe.
</objective>

<execution_context>
@/home/qualia/.claude/get-shit-done/workflows/execute-plan.md
@/home/qualia/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/24-model-resilience-voice-optimization/24-RESEARCH.md
@lib/resilience.ts
@lib/ai/providers.ts
@lib/ai/conversation-summarizer.ts
@app/api/health/route.ts
@app/(chat)/api/chat/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix circuit breaker error classification, add retry-after parsing, and add Zod validation to summarizer</name>
  <files>lib/resilience.ts, app/(chat)/api/chat/route.ts, lib/ai/conversation-summarizer.ts</files>
  <action>
**lib/resilience.ts:**

1. Add a new exported function `isTransientError(error: unknown): boolean` that returns true ONLY for errors that should trip the circuit breaker:
   - 429 (rate limit)
   - 500, 502, 503, 504 (server errors)
   - Network errors: messages containing "network", "timeout", "econnreset", "econnrefused", "fetch failed", "abort"
   - Returns FALSE for 400, 401, 403, 404 (client errors that should NOT open the circuit)
   - Check both error message strings and, if available, a `status` property on the error object

2. Add a new exported function `getRetryAfterMs(error: unknown): number | null` that extracts retry timing from error responses:
   - Check if error has `responseHeaders` property (AI SDK pattern)
   - Parse `retry-after` header: if numeric, treat as seconds and convert to ms; if date string, compute ms until that time
   - Parse `x-ratelimit-reset` header as epoch ms fallback
   - Return null if no retry-after info found
   - Cap at 120000ms (2 minutes) to prevent absurd waits

3. Modify `withRetry` to accept a new optional field `respectRetryAfter?: boolean` in RetryOptions (default true). When enabled and `getRetryAfterMs` returns a value, use that as the delay instead of the exponential backoff calculation. Still respect `maxDelay`.

**app/(chat)/api/chat/route.ts:**

4. Import `isTransientError` from `@/lib/resilience`.
5. In the `onError` callback of `streamText`, change from unconditional `recordCircuitFailure("ai-gateway")` to:
   ```
   // Only record transient errors (429, 5xx, network) as circuit breaker failures
   // Client errors (400, 401, 403) should NOT open the circuit
   if (isTransientError(error)) {
     recordCircuitFailure("ai-gateway");
   }
   ```
   Note: The `onError` callback receives the error as a parameter -- check the current signature. If it doesn't receive the error, wrap in a closure that captures it, or check if the callback signature provides it. The current code uses `onError: () => { ... }` with no parameter -- the AI SDK streamText `onError` callback DOES receive `{ error }`. Update the signature to `onError: ({ error }) => { ... }`.

**lib/ai/conversation-summarizer.ts:**

6. Add a Zod schema for the summarizer's expected JSON output:
   ```typescript
   const summarySchema = z.object({
     summary: z.string().min(1).max(2000),
     topics: z.array(z.string()).min(1).max(10),
     importance: z.number().min(1).max(10),
   });
   ```

7. Replace the manual `JSON.parse` + field extraction with Zod validation:
   - Keep the existing regex match for `{...}` JSON extraction
   - Use `summarySchema.safeParse(JSON.parse(jsonMatch[0]))`
   - On success: return `{ text: parsed.data.summary, topics: parsed.data.topics, importance: parsed.data.importance }`
   - On failure: log warning with `parsed.error.issues` and return null
   - Import z from 'zod' (already in the project, just needs import in this file)
  </action>
  <verify>
Run `pnpm build` -- no type errors. Grep for `isTransientError` in chat/route.ts to confirm usage. Grep for `safeParse` in conversation-summarizer.ts to confirm Zod validation. Grep for `getRetryAfterMs` in resilience.ts to confirm export.
  </verify>
  <done>
Circuit breaker only records transient failures (429/5xx/network). Retry-after header parsing is available in withRetry. Conversation summarizer validates JSON with Zod schema and returns null on invalid shape.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add provider-level fallback with ai-fallback and OpenRouter health probe</name>
  <files>lib/ai/providers.ts, app/api/health/route.ts</files>
  <action>
**Install dependencies:**
```bash
pnpm add @ai-sdk/google ai-fallback
```

**lib/ai/providers.ts:**

1. Import `createFallback` from `ai-fallback` and `createGoogleGenerativeAI` from `@ai-sdk/google`.

2. Add a conditional secondary provider:
   ```typescript
   const googleDirect = process.env.GOOGLE_AI_API_KEY
     ? createGoogleGenerativeAI({ apiKey: process.env.GOOGLE_AI_API_KEY })
     : null;
   ```
   If no API key, log a warning at module load: `logger.warn("GOOGLE_AI_API_KEY not set - no secondary AI provider fallback available")`

3. Create a helper function `createModelWithFallback(openRouterModel, googleModelId)` that:
   - If `googleDirect` is null: returns `wrapLanguageModel({ model: openRouterModel, middleware: safetyMiddleware })` (current behavior, no fallback)
   - If `googleDirect` exists: returns `wrapLanguageModel({ model: createFallback({ models: [openRouterModel, googleDirect(googleModelId)], onError: (error, modelId) => logger.warn({ err: error, modelId }, 'AI model failed, trying fallback'), modelResetInterval: 60_000 }), middleware: safetyMiddleware })`

   IMPORTANT: The safety middleware wraps the OUTER model (fallback-wrapped). This ensures safety checks apply regardless of which provider responds.

4. Update all four model definitions (chat-model, chat-model-reasoning, title-model, artifact-model) to use `createModelWithFallback`:
   ```typescript
   "chat-model": createModelWithFallback(
     openrouter("google/gemini-2.5-flash", {
       extraBody: { models: ["google/gemini-2.5-flash", "google/gemini-2.5-flash-lite"] },
     }),
     "gemini-2.0-flash"  // Direct Google fallback uses Gemini 2.0 Flash (widely available)
   ),
   ```
   Apply the same pattern for all four models. The direct fallback model should be `gemini-2.0-flash` since it's the stable GA equivalent.

5. Keep the test environment branch unchanged (mock models, no fallback needed).

**app/api/health/route.ts:**

6. Add an async `probeOpenRouter` function:
   ```typescript
   async function probeOpenRouter(): Promise<{ status: 'up' | 'down'; latencyMs?: number }> {
     if (!process.env.OPENROUTER_API_KEY) return { status: 'down' };
     const start = Date.now();
     try {
       const controller = new AbortController();
       const timeoutId = setTimeout(() => controller.abort(), 5000);
       const res = await fetch('https://openrouter.ai/api/v1/key', {
         headers: { Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}` },
         signal: controller.signal,
       });
       clearTimeout(timeoutId);
       return { status: res.ok ? 'up' : 'down', latencyMs: Date.now() - start };
     } catch {
       return { status: 'down' };
     }
   }
   ```

7. In the GET handler, call `probeOpenRouter()` alongside the existing Supabase check. Add the result to `services`:
   ```typescript
   const openRouterProbe = await probeOpenRouter();
   services.openrouter = { status: openRouterProbe.status, ...(openRouterProbe.latencyMs !== undefined && { latencyMs: openRouterProbe.latencyMs }) };
   if (openRouterProbe.status === 'down') overall = 'degraded';
   ```

8. Also add a `secondaryAI` status based on whether `GOOGLE_AI_API_KEY` is configured:
   ```typescript
   services['secondary-ai'] = { status: process.env.GOOGLE_AI_API_KEY ? 'up' : 'down' };
   ```
   This does NOT probe Google -- just reports configuration status. The `secondary-ai` being "down" means no fallback, which is informational but not a degraded state.
  </action>
  <verify>
Run `pnpm build` -- no type errors. Verify `ai-fallback` and `@ai-sdk/google` are in package.json. Grep for `createFallback` in providers.ts. Grep for `probeOpenRouter` in health/route.ts. Run `pnpm lint` to check for linting issues.
  </verify>
  <done>
Provider chain uses ai-fallback to try OpenRouter first, then direct Google Gemini (when configured). Health check probes OpenRouter and reports secondary AI status. Missing GOOGLE_AI_API_KEY logs a warning but does not break anything.
  </done>
</task>

</tasks>

<verification>
1. `pnpm build` passes with no type errors
2. `pnpm lint` passes
3. `grep -r "isTransientError" app/(chat)/api/chat/route.ts` shows usage in onError
4. `grep -r "safeParse" lib/ai/conversation-summarizer.ts` shows Zod validation
5. `grep -r "createFallback" lib/ai/providers.ts` shows ai-fallback integration
6. `grep -r "probeOpenRouter" app/api/health/route.ts` shows health probe
7. `grep -r "getRetryAfterMs" lib/resilience.ts` shows retry-after parsing
</verification>

<success_criteria>
- Circuit breaker ignores client errors (400/401/403) and only trips on transient failures
- Retry logic can parse and respect Retry-After headers from provider responses
- Provider fallback chain degrades gracefully: OpenRouter model fallback -> direct Google Gemini -> error
- Conversation summarizer rejects malformed AI JSON with Zod validation
- Health endpoint actively probes OpenRouter and reports AI provider status
- Everything works with only OPENROUTER_API_KEY (no GOOGLE_AI_API_KEY required)
</success_criteria>

<output>
After completion, create `.planning/phases/24-model-resilience-voice-optimization/24-01-SUMMARY.md`
</output>
