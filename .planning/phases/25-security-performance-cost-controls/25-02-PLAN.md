---
phase: 25-security-performance-cost-controls
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/db/queries/message.ts
  - lib/db/queries/index.ts
  - app/(chat)/chat/[id]/page.tsx
  - app/(chat)/api/chat/messages/route.ts
  - components/chat.tsx
  - app/(chat)/api/chat/route.ts
  - lib/supabase/middleware.ts
autonomous: true

must_haves:
  truths:
    - "Chat page loads at most 50 initial messages, not the full conversation history"
    - "User can scroll up to load older messages in long conversations"
    - "Conversation summaries are generated every 10th message, not on every response"
    - "Stream failure does not leave dangling user messages in the database"
  artifacts:
    - path: "lib/db/queries/message.ts"
      provides: "Paginated message query with cursor and count function"
      exports: ["getMessagesByChatIdPaginated", "getMessageCountByChatId"]
    - path: "app/(chat)/api/chat/messages/route.ts"
      provides: "GET endpoint for paginated message loading"
      exports: ["GET"]
    - path: "app/(chat)/chat/[id]/page.tsx"
      provides: "Server component with limited initial message load"
      contains: "INITIAL_MESSAGE_LIMIT"
    - path: "components/chat.tsx"
      provides: "Client-side scroll-to-load for older messages"
      contains: "loadOlderMessages"
    - path: "app/(chat)/api/chat/route.ts"
      provides: "Interval-based summary generation and stream failure cleanup"
      contains: "SUMMARY_INTERVAL"
  key_links:
    - from: "app/(chat)/chat/[id]/page.tsx"
      to: "lib/db/queries/message.ts"
      via: "getMessagesByChatId with limit parameter"
      pattern: "getMessagesByChatId.*limit"
    - from: "components/chat.tsx"
      to: "app/(chat)/api/chat/messages/route.ts"
      via: "fetch on scroll-up"
      pattern: "fetch.*api/chat/messages"
    - from: "app/(chat)/api/chat/route.ts"
      to: "generateConversationSummary"
      via: "interval check before calling"
      pattern: "SUMMARY_INTERVAL"
---

<objective>
Add message pagination to the chat page, optimize summary generation frequency, and clean up dangling messages on stream failure.

Purpose: Reduce initial page load time for long conversations, cut unnecessary AI API calls for summaries, and prevent ghost messages after stream errors.
Output: Paginated chat loading, interval-based summaries, stream failure message cleanup.
</objective>

<execution_context>
@/home/qualia/.claude/get-shit-done/workflows/execute-plan.md
@/home/qualia/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/25-security-performance-cost-controls/25-RESEARCH.md
@lib/db/queries/message.ts
@app/(chat)/chat/[id]/page.tsx
@components/chat.tsx
@app/(chat)/api/chat/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add paginated message loading (PERF-01)</name>
  <files>
    lib/db/queries/message.ts
    lib/db/queries/index.ts
    app/(chat)/api/chat/messages/route.ts
    app/(chat)/chat/[id]/page.tsx
    components/chat.tsx
    lib/supabase/middleware.ts
  </files>
  <action>
    **Step 1: Add paginated query and count to lib/db/queries/message.ts**

    Add a new function `getMessagesByChatIdPaginated` after the existing `getMessagesByChatId`:
    ```typescript
    export async function getMessagesByChatIdPaginated({
      id,
      limit = 50,
      before,
    }: {
      id: string;
      limit?: number;
      before?: string; // ISO timestamp cursor
    }) {
      try {
        const supabase = await createClient();
        let query = supabase
          .from("Message_v2")
          .select("*")
          .eq("chatId", id)
          .is("deletedAt", null)
          .order("createdAt", { ascending: false })
          .limit(limit);

        if (before) {
          query = query.lt("createdAt", before);
        }

        const { data, error } = await query;
        if (error) throw error;
        return (data || []).reverse(); // Return in ascending order
      } catch (_error) {
        throw new ChatSDKError(
          "bad_request:database",
          "Failed to get paginated messages",
        );
      }
    }
    ```

    Also add a `getMessageCountByChatId` function:
    ```typescript
    export async function getMessageCountByChatId({ id }: { id: string }) {
      try {
        const supabase = await createClient();
        const { count, error } = await supabase
          .from("Message_v2")
          .select("*", { count: "exact", head: true })
          .eq("chatId", id)
          .is("deletedAt", null);
        if (error) throw error;
        return count ?? 0;
      } catch (_error) {
        throw new ChatSDKError(
          "bad_request:database",
          "Failed to count messages",
        );
      }
    }
    ```

    Export both from `lib/db/queries/index.ts`.

    **Step 2: Create API endpoint app/(chat)/api/chat/messages/route.ts**

    New file for paginated message fetching:
    ```typescript
    import { z } from "zod";
    import { getChatById, getMessagesByChatIdPaginated } from "@/lib/db/queries";
    import { ChatSDKError } from "@/lib/errors";
    import { logger } from "@/lib/logger";
    import { createClient } from "@/lib/supabase/server";

    const paginationSchema = z.object({
      chatId: z.string().uuid(),
      before: z.string().datetime().optional(),
      limit: z.coerce.number().int().min(1).max(100).default(50),
    });

    export async function GET(request: Request) {
      try {
        const supabase = await createClient();
        const { data: { user } } = await supabase.auth.getUser();
        if (!user) {
          return new ChatSDKError("unauthorized:chat").toResponse();
        }

        const { searchParams } = new URL(request.url);
        const parsed = paginationSchema.safeParse({
          chatId: searchParams.get("chatId"),
          before: searchParams.get("before") || undefined,
          limit: searchParams.get("limit") || undefined,
        });

        if (!parsed.success) {
          logger.warn({ errors: parsed.error.flatten() }, "Message pagination validation failed");
          return new ChatSDKError("bad_request:api").toResponse();
        }

        const { chatId, before, limit } = parsed.data;

        // Verify ownership
        const chat = await getChatById({ id: chatId });
        if (!chat || chat.userId !== user.id) {
          return new ChatSDKError("not_found:chat").toResponse();
        }

        const messages = await getMessagesByChatIdPaginated({
          id: chatId,
          limit,
          before,
        });

        return Response.json({ messages, hasMore: messages.length === limit });
      } catch (error) {
        if (error instanceof ChatSDKError) return error.toResponse();
        logger.error({ err: error }, "Message pagination error");
        return new ChatSDKError("bad_request:database").toResponse();
      }
    }
    ```

    This route is authenticated (behind middleware), so do NOT add it to `publicApiRoutes` in middleware.ts. But DO verify it is covered by the existing auth middleware pattern (routes under `app/(chat)/api/` are already auth-gated).

    **Step 3: Modify server component app/(chat)/chat/[id]/page.tsx**

    Add limit to the message loading:
    ```typescript
    const INITIAL_MESSAGE_LIMIT = 50;

    const [messagesFromDb, totalMessageCount] = await Promise.all([
      getMessagesByChatId({ id, limit: INITIAL_MESSAGE_LIMIT }),
      getMessageCountByChatId({ id }),
    ]);
    ```

    Import `getMessageCountByChatId` from `@/lib/db/queries`.

    Pass `hasMoreMessages` to the Chat component:
    ```typescript
    const hasMoreMessages = totalMessageCount > INITIAL_MESSAGE_LIMIT;
    ```

    Add `hasMoreMessages` prop to `ChatWithErrorBoundary` (and through to `Chat`). The existing `getMessagesByChatId` already supports the `limit` parameter (it uses `get_bounded_messages` RPC when limit is provided).

    **Step 4: Add scroll-to-load in components/chat.tsx**

    Add `hasMoreMessages` prop to the Chat component interface. Add state for loading and pagination:

    ```typescript
    const [isLoadingMore, setIsLoadingMore] = useState(false);
    const [hasMore, setHasMore] = useState(hasMoreMessages ?? false);
    ```

    Add a `loadOlderMessages` callback:
    ```typescript
    const loadOlderMessages = useCallback(async () => {
      if (isLoadingMore || !hasMore || !id) return;
      setIsLoadingMore(true);
      try {
        const oldestMessage = messages[0];
        if (!oldestMessage) return;
        // Find the oldest createdAt from the current messages
        // Messages from the server have createdAt, but useChat messages may not
        // Use the message ID or a stored timestamp
        const oldestCreatedAt = (oldestMessage as any).createdAt;
        if (!oldestCreatedAt) return;

        const res = await fetch(
          `/api/chat/messages?chatId=${id}&before=${encodeURIComponent(oldestCreatedAt)}&limit=50`
        );
        if (!res.ok) return;
        const data = await res.json();
        if (data.messages && data.messages.length > 0) {
          // Convert DB messages to UI messages and prepend
          const { convertToUIMessages } = await import("@/lib/utils");
          const olderUIMessages = convertToUIMessages(data.messages);
          setMessages([...olderUIMessages, ...messages]);
          setHasMore(data.hasMore);
        } else {
          setHasMore(false);
        }
      } catch (err) {
        logger.error?.({ err }, "Failed to load older messages");
      } finally {
        setIsLoadingMore(false);
      }
    }, [isLoadingMore, hasMore, id, messages, setMessages]);
    ```

    Pass `loadOlderMessages`, `isLoadingMore`, and `hasMore` to the `Messages` component. In `Messages`, add an intersection observer or a "Load more" button at the top of the message list that triggers `loadOlderMessages` when the user scrolls to the top.

    Note: `useChat` provides `setMessages` which can be used to prepend. The `convertToUIMessages` utility already exists in `lib/utils.ts` and handles DB message -> UI message conversion.

    For simplicity, use a "Load earlier messages" button at the top of the messages area rather than infinite scroll (less risk of breaking the streaming experience). The button appears only when `hasMore` is true.

    IMPORTANT: The `messages` array from `useChat` may not have `createdAt`. The initial messages from the server DO have it (passed as `initialMessages`). For the cursor, we need to track the oldest createdAt. Store it as state initialized from the first message's createdAt, and update it when loading more.
  </action>
  <verify>
    1. `pnpm build` passes with all new files and changes.
    2. Navigate to a chat with many messages -- only 50 messages should load initially.
    3. A "Load earlier messages" button/indicator appears at the top if the chat has more than 50 messages.
    4. Clicking/triggering load-more prepends older messages without breaking the conversation flow.
  </verify>
  <done>Chat page loads limited messages initially (50). Users can load older messages on demand. Long conversations load faster. No regression in chat streaming or message display.</done>
</task>

<task type="auto">
  <name>Task 2: Optimize summary frequency and clean up stream failures (PERF-02, PERF-03)</name>
  <files>
    app/(chat)/api/chat/route.ts
  </files>
  <action>
    **PERF-02: Interval-based summary generation**

    In `app/(chat)/api/chat/route.ts`, find the `onFinish` callback section (around line 552-578) where `generateConversationSummary` is called. Currently the condition is:
    ```typescript
    if (finishedMessages.length >= 4) {
    ```

    Replace with interval-based generation:
    ```typescript
    const SUMMARY_INTERVAL = 10;
    const messageCount = finishedMessages.length;
    const shouldSummarize =
      messageCount >= 4 &&
      (messageCount === 4 || messageCount % SUMMARY_INTERVAL === 0);
    ```

    This generates a summary:
    - First time at 4 messages (initial summary)
    - Then every 10th message (at 10, 20, 30, etc.)
    - Saves ~80% of summary API calls for long conversations

    Define `SUMMARY_INTERVAL` as a constant near the top of the file (after imports, before the route handler).

    **PERF-03: Stream failure message cleanup**

    In the same file, find the `onError` callback (around line 580-588). Currently it records circuit failure and returns an error string. Add message cleanup logic.

    The challenge: the user message was already saved to the database (line 282-297) before streaming starts. On stream failure, we should soft-delete that message so the user doesn't see a "ghost" message with no response on reload.

    In the `onError` callback, add cleanup of the last saved user message. The user message ID is available as `message.id` from the request body (parsed earlier in the route). Use `after()` to delete it in the background:

    ```typescript
    onError: (error) => {
      if (isTransientError(error)) {
        recordCircuitFailure("ai-gateway");
      }
      apiLog.warn("Stream onError callback triggered");

      // Clean up dangling user message that was pre-saved before streaming
      // This prevents "ghost" messages appearing on page reload
      after(async () => {
        try {
          await deleteMessageById({ id: message.id });
          apiLog.info({ messageId: message.id }, "Cleaned up dangling user message after stream failure");
        } catch (cleanupErr) {
          apiLog.warn({ err: cleanupErr, messageId: message.id }, "Failed to clean up dangling message");
        }
      });

      return "Something went wrong generating a response. Please try again.";
    },
    ```

    Add a `deleteMessageById` function. Check if it already exists in `lib/db/queries/message.ts`. If not, add a simple soft-delete:
    ```typescript
    export async function deleteMessageById({ id }: { id: string }) {
      const supabase = await createClient();
      const { error } = await supabase
        .from("Message_v2")
        .update({ deletedAt: new Date().toISOString() })
        .eq("id", id);
      if (error) throw error;
    }
    ```

    Export from index.ts and import in the chat route.

    Note: The `message` variable is accessible in the `onError` closure because it's defined earlier in the route handler scope (from the parsed request body). Verify this by checking the variable scope -- `message` is destructured from `requestBody` around line 170-175 and is in scope for the entire handler closure including onError.

    IMPORTANT: Use `after()` from `next/server` for the cleanup so it doesn't block the error response. `after` is already imported in the chat route.
  </action>
  <verify>
    1. `pnpm build` passes.
    2. `grep -n "SUMMARY_INTERVAL" app/(chat)/api/chat/route.ts` shows the constant definition and usage.
    3. `grep -n "deleteMessageById\|dangling" app/(chat)/api/chat/route.ts` shows the cleanup logic in onError.
    4. The summary generation condition uses modulo check, not a simple `>= 4` on every message.
  </verify>
  <done>Summaries generate at messages 4, 10, 20, 30... instead of every message after 4. Stream failures clean up pre-saved user messages to prevent ghost messages on reload.</done>
</task>

</tasks>

<verification>
1. `pnpm build` passes with all changes
2. Chat page loads limited messages with pagination support
3. Summary generation uses interval-based triggering
4. Stream error cleanup is present in onError handler
5. New API endpoint `/api/chat/messages` returns paginated messages with cursor
</verification>

<success_criteria>
- Chat page loads max 50 initial messages (not full history)
- Users can load older messages on demand via button/scroll
- Summaries generate every 10th message instead of every message
- Stream failures soft-delete the pre-saved user message
- Build passes with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/25-security-performance-cost-controls/25-02-SUMMARY.md`
</output>
